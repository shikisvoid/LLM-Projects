{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZO15S-IdnHz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "zaZzlI_Ve0Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = ''"
      ],
      "metadata": {
        "id": "_-2iC7pje5aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai = OpenAI()"
      ],
      "metadata": {
        "id": "AKNka8J-fJC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant\""
      ],
      "metadata": {
        "id": "K9iJR74-fPFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def message_gpt(prompt):\n",
        "  messages = [\n",
        "      {\"role\" : \"system\" , \"content\" : system_message},\n",
        "      {\"role\" : \"user\" , \"content\" : prompt}\n",
        "  ]\n",
        "  completion = openai.chat.completions.create(\n",
        "      model = 'gpt-4o-mini',\n",
        "      messages = messages,\n",
        "  )\n",
        "  return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "PsLnI-y9fU1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shout(text):\n",
        "    print(f\"Shout has been called with input {text}\")\n",
        "    return text.upper()"
      ],
      "metadata": {
        "id": "cGx46YEBibLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\").launch()"
      ],
      "metadata": {
        "id": "7v-d8DNxiM1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
      ],
      "metadata": {
        "id": "fgJExxnqikMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view = gr.Interface(\n",
        "    fn = message_gpt,\n",
        "    inputs = [gr.Textbox(label=\"Your message:\", lines=6)],\n",
        "    outputs = [gr.Textbox(label=\"Response:\", lines=8)],\n",
        "    flagging_mode = \"never\"\n",
        ")\n",
        "\n",
        "view.launch()"
      ],
      "metadata": {
        "id": "qtRHo1w0lcSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an assistant with the personality of Sung Jin Woo. Respond with an authoritative tone, and in Markdown\"\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn = message_gpt,\n",
        "    inputs = [gr.Textbox(label=\"Your message:\", lines=6)],\n",
        "    outputs = [gr.Textbox(label=\"Response:\", lines=8)],\n",
        "    flagging_mode = \"never\"\n",
        ")\n",
        "\n",
        "view.launch()"
      ],
      "metadata": {
        "id": "pnMDj27lmJjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_gpt(prompt):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "    stream = openai.chat.completions.create(\n",
        "        model='gpt-4o-mini',\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "    result = \"\"\n",
        "    for chunk in stream:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ],
      "metadata": {
        "id": "gkMzuwUqpwX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view = gr.Interface(\n",
        "    fn=stream_gpt,\n",
        "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
        "    outputs=[gr.Markdown(label=\"Response:\")],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ],
      "metadata": {
        "id": "I6nbsV4cra9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTv3pCJnrjmZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}